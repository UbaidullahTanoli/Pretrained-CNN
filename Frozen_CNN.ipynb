{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMX0GSRa8N1fGIJaBDj7fv1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UbaidullahTanoli/Pretrained-CNN/blob/main/Frozen_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_zQfE3RjZkeq"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "8Vjy0WufZlYB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d raddar/chest-xrays-indiana-university\n",
        "!unzip chest-xrays-indiana-university.zip -d /content/dataset/"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LNFNp3oJZzrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.models import EfficientNet_B1_Weights\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "zvOuOeFYZ10_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Custom Dataset that Merges Two CSVs\n",
        "# ================================\n",
        "class PureCNNMergedDataset(Dataset):\n",
        "    def __init__(self, reports_csv, proj_csv, image_folder, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            reports_csv (str): Path to 'indiana_reports.csv', which includes the \"MeSH\" column for labels.\n",
        "            proj_csv (str): Path to 'indiana_projections.csv', which maps uid to image filename.\n",
        "            image_folder (str): Directory containing the image files.\n",
        "            transform (callable, optional): Transform to apply on images.\n",
        "        \"\"\"\n",
        "        # Load both CSVs\n",
        "        self.reports_df = pd.read_csv(reports_csv)\n",
        "        self.proj_df = pd.read_csv(proj_csv)\n",
        "        # Merge on 'uid'\n",
        "        self.data = pd.merge(self.reports_df, self.proj_df, on='uid')\n",
        "        self.image_folder = image_folder\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        # Get the image filename from the projections CSV merged with reports CSV\n",
        "        filename = row['filename']  # e.g., \"1_IM-0001-4001.dcm.png\"\n",
        "        img_path = os.path.join(self.image_folder, filename)\n",
        "\n",
        "        # Load the image and convert to RGB if needed\n",
        "        pil_image = Image.open(img_path)\n",
        "        if pil_image.mode != 'RGB':\n",
        "            pil_image = pil_image.convert('RGB')\n",
        "        if self.transform:\n",
        "            image_tensor = self.transform(pil_image)\n",
        "        else:\n",
        "            image_tensor = transforms.ToTensor()(pil_image)\n",
        "\n",
        "        # Derive binary label from the \"MeSH\" column in the reports CSV\n",
        "        # e.g., if MeSH equals \"normal\" (case-insensitive), label = 0; else, label = 1.\n",
        "        mesh_val = str(row['MeSH']).strip().lower()\n",
        "        label = 0 if mesh_val == 'normal' else 1\n",
        "\n",
        "        return image_tensor, label"
      ],
      "metadata": {
        "id": "muuo55xrZ66y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Data Transforms\n",
        "# ================================\n",
        "# Define transforms for both training and validation (no augmentation here, but you can add if needed)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "GXybrpOCaCWP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Pure CNN Model using EfficientNet-B1\n",
        "# ================================\n",
        "class PureCNNModel(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(PureCNNModel, self).__init__()\n",
        "        # Load EfficientNet-B1 pretrained on ImageNet\n",
        "        self.backbone = models.efficientnet_b1(weights=EfficientNet_B1_Weights.IMAGENET1K_V1)\n",
        "        # Get the input features of the classifier (EfficientNet-B1 typically uses 1280)\n",
        "        in_features = self.backbone.classifier[1].in_features\n",
        "        # Replace the final classifier with a new Linear layer for binary classification\n",
        "        self.backbone.classifier[1] = nn.Linear(in_features, num_classes)\n",
        "        # (Optional) Freeze parts of the network if desired\n",
        "        for param in self.backbone.features.parameters():\n",
        "             param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)"
      ],
      "metadata": {
        "id": "-2bbvkzMaOzu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Training and Evaluation Functions\n",
        "# ================================\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    preds_all, labels_all = [], []\n",
        "\n",
        "    for images, labels in dataloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        preds_all.extend(preds.cpu().numpy())\n",
        "        labels_all.extend(labels.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = accuracy_score(labels_all, preds_all)\n",
        "    epoch_prec = precision_score(labels_all, preds_all, zero_division=0)\n",
        "    epoch_rec = recall_score(labels_all, preds_all, zero_division=0)\n",
        "    epoch_f1 = f1_score(labels_all, preds_all, zero_division=0)\n",
        "    return epoch_loss, epoch_acc, epoch_prec, epoch_rec, epoch_f1\n",
        "\n",
        "def eval_epoch(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    preds_all, labels_all = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            preds_all.extend(preds.cpu().numpy())\n",
        "            labels_all.extend(labels.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = accuracy_score(labels_all, preds_all)\n",
        "    epoch_prec = precision_score(labels_all, preds_all, zero_division=0)\n",
        "    epoch_rec = recall_score(labels_all, preds_all, zero_division=0)\n",
        "    epoch_f1 = f1_score(labels_all, preds_all, zero_division=0)\n",
        "    return epoch_loss, epoch_acc, epoch_prec, epoch_rec, epoch_f1"
      ],
      "metadata": {
        "id": "O3amq4slaUSN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Main Training Loop\n",
        "# ================================\n",
        "def main():\n",
        "    # Paths to the CSV files and image folder\n",
        "    reports_csv = '/content/dataset/indiana_reports.csv'\n",
        "    proj_csv = '/content/dataset/indiana_projections.csv'\n",
        "    image_folder = '/content/dataset/images/images_normalized'\n",
        "\n",
        "    # Create the merged dataset that includes image filenames and labels\n",
        "    full_dataset = PureCNNMergedDataset(reports_csv, proj_csv, image_folder, transform=transform)\n",
        "\n",
        "    # Split the dataset (80% training, 20% testing)\n",
        "    total_size = len(full_dataset)\n",
        "    train_size = int(0.8 * total_size)\n",
        "    test_size = total_size - train_size\n",
        "    train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "    # Create DataLoaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
        "    test_loader  = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Set device (GPU if available)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Instantiate the pure CNN model and move to device\n",
        "    model = PureCNNModel(num_classes=2).to(device)\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    num_epochs = 40  # You can adjust this as needed\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, train_acc, train_prec, train_rec, train_f1 = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, val_acc, val_prec, val_rec, val_f1 = eval_epoch(model, test_loader, criterion, device)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        print(f\"  Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | Prec: {train_prec:.4f} | Rec: {train_rec:.4f} | F1: {train_f1:.4f}\")\n",
        "        print(f\"  Val   Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | Prec: {val_prec:.4f} | Rec: {val_rec:.4f} | F1: {val_f1:.4f}\")"
      ],
      "metadata": {
        "id": "eAgjg-8FaWXQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6nvzHjqyaYg0",
        "outputId": "8a55e985-3712-43f5-96d3-b59fea016bc1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b1_rwightman-bac287d4.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b1_rwightman-bac287d4.pth\n",
            "100%|██████████| 30.1M/30.1M [00:00<00:00, 72.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "  Train Loss: 0.6296 | Acc: 0.6517 | Prec: 0.6860 | Rec: 0.8376 | F1: 0.7543\n",
            "  Val   Loss: 0.6047 | Acc: 0.6680 | Prec: 0.7427 | Rec: 0.7396 | F1: 0.7411\n",
            "Epoch 2/40\n",
            "  Train Loss: 0.6209 | Acc: 0.6606 | Prec: 0.7035 | Rec: 0.8092 | F1: 0.7527\n",
            "  Val   Loss: 0.5882 | Acc: 0.6921 | Prec: 0.7159 | Rec: 0.8635 | F1: 0.7828\n",
            "Epoch 3/40\n",
            "  Train Loss: 0.6117 | Acc: 0.6685 | Prec: 0.7107 | Rec: 0.8103 | F1: 0.7572\n",
            "  Val   Loss: 0.5997 | Acc: 0.6760 | Prec: 0.7537 | Rec: 0.7365 | F1: 0.7450\n",
            "Epoch 4/40\n",
            "  Train Loss: 0.6172 | Acc: 0.6668 | Prec: 0.7093 | Rec: 0.8098 | F1: 0.7562\n",
            "  Val   Loss: 0.5908 | Acc: 0.6814 | Prec: 0.7224 | Rec: 0.8187 | F1: 0.7676\n",
            "Epoch 5/40\n",
            "  Train Loss: 0.6128 | Acc: 0.6691 | Prec: 0.7104 | Rec: 0.8129 | F1: 0.7582\n",
            "  Val   Loss: 0.6476 | Acc: 0.6573 | Prec: 0.7979 | Rec: 0.6250 | F1: 0.7009\n",
            "Epoch 6/40\n",
            "  Train Loss: 0.6072 | Acc: 0.6746 | Prec: 0.7163 | Rec: 0.8116 | F1: 0.7610\n",
            "  Val   Loss: 0.6139 | Acc: 0.6760 | Prec: 0.7692 | Rec: 0.7083 | F1: 0.7375\n",
            "Epoch 7/40\n",
            "  Train Loss: 0.6075 | Acc: 0.6775 | Prec: 0.7169 | Rec: 0.8174 | F1: 0.7639\n",
            "  Val   Loss: 0.6024 | Acc: 0.6700 | Prec: 0.7395 | Rec: 0.7510 | F1: 0.7452\n",
            "Epoch 8/40\n",
            "  Train Loss: 0.6125 | Acc: 0.6715 | Prec: 0.7147 | Rec: 0.8077 | F1: 0.7583\n",
            "  Val   Loss: 0.6085 | Acc: 0.6774 | Prec: 0.7500 | Rec: 0.7469 | F1: 0.7484\n",
            "Epoch 9/40\n",
            "  Train Loss: 0.6134 | Acc: 0.6743 | Prec: 0.7174 | Rec: 0.8079 | F1: 0.7600\n",
            "  Val   Loss: 0.6076 | Acc: 0.6707 | Prec: 0.7246 | Rec: 0.7865 | F1: 0.7542\n",
            "Epoch 10/40\n",
            "  Train Loss: 0.6116 | Acc: 0.6680 | Prec: 0.7127 | Rec: 0.8037 | F1: 0.7555\n",
            "  Val   Loss: 0.6095 | Acc: 0.6700 | Prec: 0.7580 | Rec: 0.7146 | F1: 0.7357\n",
            "Epoch 11/40\n",
            "  Train Loss: 0.6130 | Acc: 0.6807 | Prec: 0.7221 | Rec: 0.8121 | F1: 0.7645\n",
            "  Val   Loss: 0.6081 | Acc: 0.6673 | Prec: 0.7327 | Rec: 0.7594 | F1: 0.7458\n",
            "Epoch 12/40\n",
            "  Train Loss: 0.6056 | Acc: 0.6772 | Prec: 0.7192 | Rec: 0.8105 | F1: 0.7622\n",
            "  Val   Loss: 0.6441 | Acc: 0.6426 | Prec: 0.7689 | Rec: 0.6344 | F1: 0.6952\n",
            "Epoch 13/40\n",
            "  Train Loss: 0.6095 | Acc: 0.6765 | Prec: 0.7181 | Rec: 0.8116 | F1: 0.7620\n",
            "  Val   Loss: 0.6110 | Acc: 0.6747 | Prec: 0.7418 | Rec: 0.7573 | F1: 0.7495\n",
            "Epoch 14/40\n",
            "  Train Loss: 0.6081 | Acc: 0.6700 | Prec: 0.7123 | Rec: 0.8100 | F1: 0.7580\n",
            "  Val   Loss: 0.6070 | Acc: 0.6653 | Prec: 0.7431 | Rec: 0.7323 | F1: 0.7377\n",
            "Epoch 15/40\n",
            "  Train Loss: 0.6129 | Acc: 0.6735 | Prec: 0.7163 | Rec: 0.8084 | F1: 0.7596\n",
            "  Val   Loss: 0.6002 | Acc: 0.6780 | Prec: 0.7129 | Rec: 0.8354 | F1: 0.7693\n",
            "Epoch 16/40\n",
            "  Train Loss: 0.6145 | Acc: 0.6748 | Prec: 0.7158 | Rec: 0.8134 | F1: 0.7615\n",
            "  Val   Loss: 0.6089 | Acc: 0.6754 | Prec: 0.7540 | Rec: 0.7344 | F1: 0.7441\n",
            "Epoch 17/40\n",
            "  Train Loss: 0.6170 | Acc: 0.6768 | Prec: 0.7186 | Rec: 0.8113 | F1: 0.7621\n",
            "  Val   Loss: 0.5936 | Acc: 0.6834 | Prec: 0.7282 | Rec: 0.8094 | F1: 0.7667\n",
            "Epoch 18/40\n",
            "  Train Loss: 0.6126 | Acc: 0.6733 | Prec: 0.7152 | Rec: 0.8111 | F1: 0.7601\n",
            "  Val   Loss: 0.5938 | Acc: 0.6894 | Prec: 0.7091 | Rec: 0.8760 | F1: 0.7838\n",
            "Epoch 19/40\n",
            "  Train Loss: 0.6133 | Acc: 0.6748 | Prec: 0.7148 | Rec: 0.8161 | F1: 0.7621\n",
            "  Val   Loss: 0.5940 | Acc: 0.6801 | Prec: 0.7429 | Rec: 0.7677 | F1: 0.7551\n",
            "Epoch 20/40\n",
            "  Train Loss: 0.6060 | Acc: 0.6857 | Prec: 0.7247 | Rec: 0.8184 | F1: 0.7687\n",
            "  Val   Loss: 0.6129 | Acc: 0.6747 | Prec: 0.7599 | Rec: 0.7219 | F1: 0.7404\n",
            "Epoch 21/40\n",
            "  Train Loss: 0.6167 | Acc: 0.6730 | Prec: 0.7152 | Rec: 0.8100 | F1: 0.7597\n",
            "  Val   Loss: 0.6242 | Acc: 0.6586 | Prec: 0.7563 | Rec: 0.6917 | F1: 0.7225\n",
            "Epoch 22/40\n",
            "  Train Loss: 0.6085 | Acc: 0.6738 | Prec: 0.7158 | Rec: 0.8108 | F1: 0.7603\n",
            "  Val   Loss: 0.6134 | Acc: 0.6707 | Prec: 0.7653 | Rec: 0.7031 | F1: 0.7329\n",
            "Epoch 23/40\n",
            "  Train Loss: 0.6108 | Acc: 0.6716 | Prec: 0.7144 | Rec: 0.8087 | F1: 0.7586\n",
            "  Val   Loss: 0.6294 | Acc: 0.6533 | Prec: 0.7558 | Rec: 0.6802 | F1: 0.7160\n",
            "Epoch 24/40\n",
            "  Train Loss: 0.6200 | Acc: 0.6713 | Prec: 0.7121 | Rec: 0.8140 | F1: 0.7596\n",
            "  Val   Loss: 0.6025 | Acc: 0.6747 | Prec: 0.7554 | Rec: 0.7302 | F1: 0.7426\n",
            "Epoch 25/40\n",
            "  Train Loss: 0.6055 | Acc: 0.6864 | Prec: 0.7245 | Rec: 0.8205 | F1: 0.7695\n",
            "  Val   Loss: 0.5934 | Acc: 0.6760 | Prec: 0.7179 | Rec: 0.8167 | F1: 0.7641\n",
            "Epoch 26/40\n",
            "  Train Loss: 0.6081 | Acc: 0.6807 | Prec: 0.7191 | Rec: 0.8200 | F1: 0.7662\n",
            "  Val   Loss: 0.6076 | Acc: 0.6707 | Prec: 0.6973 | Rec: 0.8615 | F1: 0.7707\n",
            "Epoch 27/40\n",
            "  Train Loss: 0.6033 | Acc: 0.6817 | Prec: 0.7239 | Rec: 0.8103 | F1: 0.7646\n",
            "  Val   Loss: 0.6116 | Acc: 0.6680 | Prec: 0.7549 | Rec: 0.7156 | F1: 0.7348\n",
            "Epoch 28/40\n",
            "  Train Loss: 0.6087 | Acc: 0.6785 | Prec: 0.7197 | Rec: 0.8126 | F1: 0.7634\n",
            "  Val   Loss: 0.6351 | Acc: 0.6546 | Prec: 0.7768 | Rec: 0.6490 | F1: 0.7072\n",
            "Epoch 29/40\n",
            "  Train Loss: 0.6234 | Acc: 0.6648 | Prec: 0.7115 | Rec: 0.7985 | F1: 0.7525\n",
            "  Val   Loss: 0.5973 | Acc: 0.6780 | Prec: 0.7503 | Rec: 0.7479 | F1: 0.7491\n",
            "Epoch 30/40\n",
            "  Train Loss: 0.5988 | Acc: 0.6803 | Prec: 0.7212 | Rec: 0.8137 | F1: 0.7646\n",
            "  Val   Loss: 0.5921 | Acc: 0.6814 | Prec: 0.7345 | Rec: 0.7896 | F1: 0.7610\n",
            "Epoch 31/40\n",
            "  Train Loss: 0.6098 | Acc: 0.6782 | Prec: 0.7157 | Rec: 0.8224 | F1: 0.7653\n",
            "  Val   Loss: 0.5931 | Acc: 0.6948 | Prec: 0.7329 | Rec: 0.8260 | F1: 0.7767\n",
            "Epoch 32/40\n",
            "  Train Loss: 0.6055 | Acc: 0.6795 | Prec: 0.7211 | Rec: 0.8116 | F1: 0.7637\n",
            "  Val   Loss: 0.6118 | Acc: 0.6740 | Prec: 0.7471 | Rec: 0.7448 | F1: 0.7460\n",
            "Epoch 33/40\n",
            "  Train Loss: 0.6140 | Acc: 0.6792 | Prec: 0.7212 | Rec: 0.8105 | F1: 0.7633\n",
            "  Val   Loss: 0.5981 | Acc: 0.6827 | Prec: 0.7102 | Rec: 0.8552 | F1: 0.7760\n",
            "Epoch 34/40\n",
            "  Train Loss: 0.6063 | Acc: 0.6775 | Prec: 0.7188 | Rec: 0.8124 | F1: 0.7627\n",
            "  Val   Loss: 0.6003 | Acc: 0.6867 | Prec: 0.7316 | Rec: 0.8094 | F1: 0.7685\n",
            "Epoch 35/40\n",
            "  Train Loss: 0.6167 | Acc: 0.6767 | Prec: 0.7174 | Rec: 0.8140 | F1: 0.7626\n",
            "  Val   Loss: 0.6014 | Acc: 0.6720 | Prec: 0.7251 | Rec: 0.7885 | F1: 0.7555\n",
            "Epoch 36/40\n",
            "  Train Loss: 0.6044 | Acc: 0.6792 | Prec: 0.7203 | Rec: 0.8129 | F1: 0.7638\n",
            "  Val   Loss: 0.5955 | Acc: 0.6941 | Prec: 0.7244 | Rec: 0.8458 | F1: 0.7804\n",
            "Epoch 37/40\n",
            "  Train Loss: 0.6120 | Acc: 0.6777 | Prec: 0.7194 | Rec: 0.8113 | F1: 0.7626\n",
            "  Val   Loss: 0.6281 | Acc: 0.6580 | Prec: 0.7702 | Rec: 0.6667 | F1: 0.7147\n",
            "Epoch 38/40\n",
            "  Train Loss: 0.6155 | Acc: 0.6716 | Prec: 0.7142 | Rec: 0.8092 | F1: 0.7588\n",
            "  Val   Loss: 0.6034 | Acc: 0.6861 | Prec: 0.7061 | Rec: 0.8760 | F1: 0.7820\n",
            "Epoch 39/40\n",
            "  Train Loss: 0.6008 | Acc: 0.6885 | Prec: 0.7279 | Rec: 0.8176 | F1: 0.7701\n",
            "  Val   Loss: 0.6159 | Acc: 0.6660 | Prec: 0.7497 | Rec: 0.7208 | F1: 0.7350\n",
            "Epoch 40/40\n",
            "  Train Loss: 0.6050 | Acc: 0.6808 | Prec: 0.7210 | Rec: 0.8153 | F1: 0.7653\n",
            "  Val   Loss: 0.5950 | Acc: 0.6774 | Prec: 0.7281 | Rec: 0.7948 | F1: 0.7600\n"
          ]
        }
      ]
    }
  ]
}